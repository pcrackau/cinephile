{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c0d937",
   "metadata": {},
   "source": [
    "## Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f151267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa63c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../finetune_data/output/\"\n",
    "\n",
    "train_dir = PATH + \"train\"\n",
    "val_dir = PATH + \"val\"\n",
    "\n",
    "num_classes = 5\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647fdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, accuracy, device):\n",
    "    \n",
    "  epoch_loss = 0\n",
    "  epoch_cor = 0.0\n",
    "  total_samples = 0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  pbar = tqdm(total=len(iterator), dynamic_ncols=True)\n",
    "  \n",
    "  for (x, y) in iterator:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    cor, n_samples = accuracy(y_pred, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    epoch_loss += loss.item()\n",
    "    epoch_cor += cor\n",
    "    total_samples += n_samples\n",
    "\n",
    "    pbar.update(1) \n",
    "  epoch_loss /= len(iterator)\n",
    "  epoch_acc = epoch_cor / total_samples\n",
    "  pbar.close()\n",
    "      \n",
    "  return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, accuracy, device):\n",
    "    \n",
    "  epoch_loss = 0\n",
    "  epoch_cor = 0.0\n",
    "  total_samples = 0\n",
    "  \n",
    "  model.eval()\n",
    "\n",
    "  pbar = tqdm(total=len(iterator), dynamic_ncols=True)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for (x, y) in iterator:\n",
    "\n",
    "      x = x.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      y_pred = model(x)\n",
    "\n",
    "      loss = criterion(y_pred, y)\n",
    "\n",
    "      correct, n_samples = accuracy(y_pred, y)\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_cor += correct\n",
    "      total_samples += n_samples\n",
    "\n",
    "      pbar.update(1)\n",
    "      \n",
    "  epoch_loss /= len(iterator)\n",
    "  epoch_acc = epoch_cor/total_samples\n",
    "\n",
    "  pbar.close()\n",
    "      \n",
    "  return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48c82845",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "def calc_accuracy(pred, target):\n",
    "    \n",
    "    pred = softmax(pred)\n",
    "    pred = torch.argmax(pred, dim=-1)\n",
    "\n",
    "    correct = torch.sum(pred==target)\n",
    "\n",
    "    return correct, len(target)\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose(\n",
    "        [transforms.Grayscale(num_output_channels=3), transforms.Resize(224), \\\n",
    "         transforms.CenterCrop((224,224)), transforms.ToTensor(), \\\n",
    "         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    "    ),\n",
    "    'val': transforms.Compose(\n",
    "        [transforms.Grayscale(num_output_channels=3), transforms.Resize(224), \\\n",
    "         transforms.CenterCrop((224,224)), transforms.ToTensor(), \\\n",
    "         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3188fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torchvision.models import vgg16, vgg16_bn\n",
    "\n",
    "model_name = \"shottypes_vgg16_bn\"\n",
    "device = \"mps\"\n",
    "EPOCHS = 12\n",
    "n_class = 5\n",
    "model = vgg16_bn(pretrained=True)\n",
    "\n",
    "model.classifier[0] = torch.nn.Linear(7 * 7 * 512, 4096)\n",
    "model.classifier[3] = torch.nn.Linear(4096, 4096)\n",
    "model.classifier[6] = torch.nn.Linear(4096, n_class)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "train_set = datasets.ImageFolder(train_dir, data_transforms['train'])\n",
    "val_set = datasets.ImageFolder(val_dir, data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=32, num_workers=8)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=32, num_workers=8)\n",
    "\n",
    "optimizer = Adam([\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4} \n",
    "])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('+inf')\n",
    "best_epoch = 0\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(\"EPOCH:\", epoch+1)\n",
    "\n",
    "    train_loss, train_acc_1 = train(model, train_loader, optimizer, criterion, calc_accuracy, device)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tTrain Acc @1: {train_acc_1*100:6.2f}%')\n",
    "\n",
    "    valid_loss, valid_acc_1 = evaluate(model, val_loader, criterion, calc_accuracy, device)\n",
    "    \n",
    "    print(f'\\tValid Loss: {valid_loss:.3f}')\n",
    "    print(f'\\tValid Acc @1: {valid_acc_1*100:6.2f}%')\n",
    "    \n",
    "    if best_valid_loss > valid_loss:        \n",
    "        filename = model_name + '.pt'\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            os.remove(filename)\n",
    "        best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc_1\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        print(f\"\\tEpoch {best_epoch} saved\")\n",
    "\n",
    "    print(f'\\tBest Valid Loss @1: {best_valid_loss:.3f} in Epoch {best_epoch}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
